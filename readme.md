# Проект для обучения многослойных ИНС прямого распространения методом обратного распространения ошибки
## 1 Общие положения
В текущем состоянии проект предоставляет возможность реализации запуска серии экспериментов, в рамках которых будут независимо выполнены попытки обучения для заданных конфигураций; при этом запуск обучения для каждой одной отдельной конфигурации может быть выполнен несколько раз для исключения влияния случайного характера инициализации параметров сети. Топология сети, настройки обучения и особенности обучающей выборки могут быть гибко изменены.  
Хотя основная часть проекта, связанная непосредственно с обучением сети, независима от специфики решаемой задачи, однако цель проекта - обучение нейросетевых аппроксиматоров, воспроизводящих заданную математическую зависимость произвольного числа аргументов.

Сеть в данном проекте представляется набором слоёв и функцией потери. Сеть имеет методы для реализации прямого и обратного проходов. На прямом проходе для заданного входа вычисляется выходное значение. На обратном проходе по заданным целевым значениям и результатам прямого прохода вычисляются градиенты.  
Остальные компоненты сети также имеют методы для прямого и обратного проходов.  
Функция потери позволяет оценивать точность работы сети.  
Слой представляет собой набор операций.  
Операции подразделяются на операции без параметра (например, функции активации) и операции с параметром (например, взвешивание, где параметром являются весовые коэффициенты).  
Непосредственно обучение выполняется тренером. Правило корректировки параметров сети задаётся в оптимизаторе.

Алгоритм обратного распространения ошибки является алгоритмом обучения с учителем, поэтому перед запуском обучения необходимо предварительно сформировать обучающую выборку.

Таким образом, для запуска обучения необходимо выполнить следующие базовые шаги:
1. Подготовить обучающую выборку;
2. Инициализировать сеть;
3. Инициализировать оптимизатор;
4. Запустить обучение с помощью тренера.

В основе вычислений проекта лежит класс models.math.Matrix, представляющий собой обёртку вокруг двумерного массива вещественных чисел. Класс имеет множество методов для выполнения различных матричных операций.  

### 1.1 Подготовка обучающей выборки
#### 1.1.1 Представление обучающей выборки
Для представления обучающей выборки был разработан класс models.data.Dataset, который агрегирует данные для обучения, тестов и валидации.
> Данные для обучения используются при обучении. Данные для тестов используются для оценки работы сети во время обучения. Данные для валидации используются для оценки сети вне рамок обучения.

Для представления части обучающей выборки был разработан класс models.data.Data, который объединяет входные данные и соответствующие им требуемые выходные данные, представленные матрицами.  
#### 1.1.2 Формирование обучающей выборки
Для формирования обучающей выборки для обучения аппроксиматора разработан класс models.data.approximation.ApproxDataLoader. Его метод ApproximationDataLoader.load принимает объект типа models.data.approximation.ApproxLoadParameters, который позволяет задать различные параметры обучающей выборки, а именно:
* **функция** - объект абстрактного типа models.data.approximation.functions.Function, представляющий собой воспроизводимую аппроксиматором функцию, который позволяет задать:
    * **строковое представление** функции (например, 'sin(x)');
    * **границы диапазона** изменения входных переменных - при формировании выборки входные значения по каждой из входных переменных будут формироваться в соответствии с заданными границами (например, [0, 1] для первой переменной, [3, 3.5] для второй, и т.д.);
* **размер выборки** - количество отсчётов, которые будут взяты по каждой входной переменной из указанных для функции границ;
> **Внимание!** Для функций от нескольких переменных отсчёты объединяются с помощью декартового произведения, что может привести к **большим** размерам итоговой обучающей выборки. Например, если указать размер выборки 100 для функции трёх переменных, то итоговая обучающая выборка будет иметь размер ``100 * 100 * 100 = 1 000 000``
* доля **тестовой** выборки - какую часть **размер выборки** составляет размер тестовой выборки (от 0 до 1);
* доля **валидационной** выборки - какую часть **размер выборки** составляет размер валидационной выборки (от 0 до 1);
* коэффициент **расширения** границ переменных - во сколько раз может быть расширена обучающая выборка (например, границы [1, 2] при коэффициенте расширения 1.3 будут расширены до [0.85, 2.15]);
#### 1.1.3 Представление функций для воспроизведения аппроксиматором
Примеры функций находятся в пакете models.data.approximation.functions.examples. Для добавления новой функции необходимо создать класс, унаследовав его от models.data.approximation.functions.Function и реализовав его абстрактные методы. Обратите внимание на сигнатуру метода Function.calculate, который принимает на вход массив - это позволяет реализовывать функции произвольного числа аргументов. Контроль за соответствием размерности массива количеству аргументов функции остаётся за пользователем класса.  
#### 1.1.4 Пример
Пример создания обучающей выборки для функции 'sin(x)' на интервале [0, 3.14]:

    List<VariableRange> ranges = Arrays.asList(new VariableRange(0, 3.14));  // границы диапазона изменения входных переменных
    Function function = new SinX(ranges);  // функция, на воспроизведение которой необходимо обучить сеть
    ApproximationLoadParameters parameters = new ApproximationLoadParameters(
                function,  // функция
                256,  // размер выборки
                0.5,  // часть выборки для тестов
                0.25,  // часть выборки для валидации
                1.3);  // коэффициент расширения
    Dataset dataset = new ApproximationDataLoader().load(parameters);  // обучающая выборка
### 1.2 Инициализация сети
#### 1.2.1 Представление сети и её компонентов
Для представления сети был разработан класс models.networks.Network, который агрегирует функцию потерь (абстрактный класс models.losses.Loss) и список слоёв (абстрактный класс models.layers.Layer). Сеть является комплексным объектом, поэтому при разработке соответствующего класса был применен шаблон проектирования "Строитель" (Builder). Использование этого шаблона позволяет задать правила создания объекта, после чего создавать произвольное количество объектов в соответствии с правилами.
##### 1.2.1.1 Слой
Таким образом, для инициализации сети необходимо предварительно инициализировать слои и функцию потери. В общем случае функция потери лишь задаёт правило оценки работы сети, поэтому её инициализация не требует указания дополнительных параметров. Для инициализации слоёв (а именно, полносвязных слоёв, представленных классом models.layers.DenseLayer, который является наследником models.layers.Layer) требуется указать:
* количество входов слоя;
* количество нейронов слоя;
* функцию активации - объект абстрактного типа models.operations.Operation.

Сам слой характеризуется:
* размером - количество нейронов слоя;
* набором операций - объекты абстрактного типа models.operations.Operation, представляющие операции, которые выполняются при прохождении сигналов через слой.
##### 1.2.1.2 Операция
Операция является базовым компонентом сети. Именно операции определяют ход вычислений, выполняемых сетью. Операции имеют методы для реализации прямого (вычисление результата) и обратного (вычисление градиентов) проходов.
Операции подразделяются:
* операция без параметра - функции активации;
* операции с параметром - взвешивание (параметр - весовые коэффициенты) и смещение (параметр - смещения), их особенность заключается в необходимости вычислений градиентов по параметрам при обратном проходе.
#### 1.2.2 Шаблон "Строитель"
Для упрощения создания сети был разработан дополнительный "Строитель", позволяющий строить сеть по указанным размерам слоёв и их функциям активации. При этом размеры указываются следующим образом: "<количество_входов_сети>, <размер_скрытого_слоя_1>, ..., <размер_скрытого_слоя_N>, <количество_выходов_сети>". При этом функции активации указываются только для скрытых и выходного слоёв.
Далее будут приведены примеры создания сети со среднеквадратической функцией потерь и со следующей конфигурацией слоёв:
1. Входной слой, размерность равна 2;
2. Скрытый слой 1, размерность 16, логистическая функция активации;
3. Скрытый слой 2, размерность 4, функция активации - гиперболический тангенс;
4. Выходной слоя, размерность равна 1, функция активации - линейная. 
#### 1.2.3 Примеры
##### 1.2.3.1 Пример создания сети без использования "Строителя"

    Loss loss = new MeanSquaredError();  // среднеквадратичная функция потерь
    Layer layer1 = new DenseLayer(2,  // количество входов
                                  16, // количество нейронов слоя
                                  new Sigmoid());  // функция активации
    Layer layer2 = new DenseLayer(16, 4, new Tanh());
    Layer layer3 = new DenseLayer(4, 1, new Linear());
    List<Layer> layers = Arrays.asList(layer1, layer2, layer3);
    Network network = new Network(layers,  // набор слоёв сети 
                                  loss);   // функция потерь
##### 1.2.3.2 Пример создания сети с использованием обычного "Строителя"

    Loss loss = new MeanSquaredError();  // среднеквадратичная функция потерь
    Layer layer1 = new DenseLayer(2,  // количество входов
                                  16, // количество нейронов слоя
                                  new Sigmoid());  // функция активации
    Layer layer2 = new DenseLayer(16, 4, new Tanh());
    Layer layer3 = new DenseLayer(4, 1, new Linear());
    List<Layer> layers = Arrays.asList(layer1, layer2, layer3);
    Network.Builder builder = new Network.BasicBuilder()  // создание строителя
        .layers(layers)  // задание набора слоёв сети
        .loss(loss);  // задание функции потерь
    Network network1 = builder.build();  // создание одного экземпляра   
    Network network2 = builder.build();  // создание второго экземпляра
При использовании обычного "Строителя" создаются разные объекты сети, **равные** между собой по **содержанию**. 
Использование такого "Строителя" позволяет пересоздавать одну и ту же сеть для обучения её по разным правилам.

##### 1.2.3.3 Пример создания сети с использованием другого "Строителя"

    Loss loss = new MeanSquaredError();  // среднеквадратичная функция потерь
    List<Integer> layerSizes = Arrays.asList(2, 16, 4, 1);
    Operation activation1 = new Sigmoid();
    Operation activation2 = new Tanh();
    Operation activation3 = new Linear();
    List<Operation> operations = Arrays.asList(activation1, 
                                               activation2, 
                                               activation3);
    Network.Builder builder = new Network.AnotherBuilder()  // создание строителя
        .sizes(layerSizes)  // задание размеров слоёв сети
        .activations(activations)  // задание функций активаций слоёв сети
        .loss(loss);  // задание функции потерь
    Network network1 = builder.build();  // создание одного экземпляра   
    Network network2 = builder.build();  // создание второго экземпляра
При использовании данного "Строителя" создаются разные объекты сети, **разные** между собой по **содержанию**. 
Использование такого "Строителя" позволяет создавать разные сети с одинаковой топологией (с точки зрения размеров и функций активации) с разными значениями весов и смещений для обучения с целью получения наилучших результатов для заданной топологии.
### 1.3 Инициализация оптимизатора
Оптимизатор задаёт правило корректировки параметров сети. Для его представления был разработан абстрактный класс models.optimizers.Optimizer. Его метод Optimizer.step выполняет корректировку параметров сети после выполнения обратного прохода с учётом скорости обучения. Оптимизатор поддерживает снижение скорости обучения. Оптимизатор характеризуется:
* сетью, которую необходимо обучать;
* текущей скоростью обучения;
* величиной снижения скорости обучения.

Параметры, влияющие на вычисление величины скорости обучения:
* начальная скорость обучения;
* конечная скорость обучения;
* количество эпох обучения.

Так как эти параметры задаются на разных этапах выполнения программы, то для оптимизатора также был применён шаблон "Строитель". Например, длительность обучения является характеристикой обучения, поэтому оптимизатор не может быть сформирован ранее начала обучения. Также и сеть не может быть задана ранее обучения. При этом начальные и конечные скорости обучения относятся непосредственно к оптимизатору и задаются при подготовке к обучению.
#### 1.3.1 Примеры
Далее приведены примеры создания оптимизатора, реализующего стохастический градиентный спуск (класс models.optimizers.SGD, наследник models.optimizers.Optimizer), с начальной скоростью обучения 0.1 и конечной 0.0001 при длительности обучения в 1000 эпох.
##### 1.3.1.1 Создание оптимизатора без "Строителя"

    Network network = builder.build(); // см. пример в 2.3.2/2.3.3
    double startLR = 0.1;  // начальная скорость обучения
    double stopLR = 0.0001; // конечная скрость обучения
    int epochs = 1000;  // количество эпох обучения
    double decayLR = (startLR - stopLR) / (epochs - 1);  // величина снижения скрости обучения
    Optimizer optimizer = new Optimizer(network, startLR, decayLR);
Основным недостатком данного способа инициализации состоит в том, что отдельные объекты из листинга выше могут быть доступны в разных контекстах. Тогда при частичном заполнении объекта и при передаче его между контекстами необходимо дополнительно контролировать заполненность полей объекта.
##### 1.3.1.2 Создание оптимизатора со "Строителем"

    Network network = builder.build(); // см. пример в 2.3.2/2.3.3
    double startLR = 0.1;  // начальная скорость обучения
    double stopLR = 0.0001; // конечная скрость обучения
    int epochs = 1000;  // количество эпох обучения
    Optimizer.Builder optimBuilder = new SGD.Builder()
        .startLR(startLR)
        .stopLR(stopLR)
        .epochs(epochs)
        .network(network);
    Optimizer optimizer = optimBuilder.build();  // проверка полей, расчёт величины снижения и создание объекта
При использовании "Строителя" различные параметры могут быть заданы в различных частях программы, на разных этапах её выполнения и в разных контекстах, но при этом гарантируется, что созданный объект будет полностью корректно инициализирован.
### 1.4 Запуск обучения
Обучение реализовано с помощью метода fit класса models.trainers.Trainer. Метод принимает на вход объект типа models.trainers.FitParameters, который позволяет задать следующие параметры для обучения:
* обучающая выборка;
* количество эпох обучения;
* размер пакета - размер пакетов, на которые разбивается обучающая выборка (это позволяет избежать выполнения матричных операций с большими массивами);
* количество опросов - сколько раз во время обучения необходимо вычислить потерю сети на тестовой выборке;
* признак ранней остановки - при обучении текущая потеря будет сравниваться с предыдущими результатами (если при этом окажется, что новые результаты хуже предыдущих, то обучение останавливается);
* необходимость использования механизма предобучения;
* количество попыток предобучения - сколько раз будет выполняться предобучения;
* множитель для снижения длительности обучения - во сколько раз будет снижено количество эпох при предобучении;
* "Строитель" сети - использование именно строителя позволяет пересоздавать сети с одинаковой топологией, но разными весовыми коэффициентами;
* "Строитель" оптимизатор - так как количество эпох обучения задаётся именно во время обучения и сеть генерируется также во время обучения, то для корректной инициализации оптимизатора также требуется создать его именно во время обучения;
* метод опроса;

При обучении отслеживается текущий и наилучший результаты. Если по окончании обучения текущий результат хуже наилучшего, то метод возвращает сеть, обеспечившую именно наилучший результат. 

Метод возвращает объект типа models.trainers.FitResults, который характеризуется:
* зависимостью потери на тестовой выборки от номера эпохи;
* обученной сетью;
* достигнутой точностью - объект типа utils.Errors, который характеризуется:
    * максимальной абсолютной ошибкой - скаляр, основной показатель точности сети, вычисляется как максимальная разность между выходом сети и соответствующим ему требуемым результатом;
    * максимальной относительной ошибкой - скаляр, вычисляется как отношение максимальной абсолютной ошибки к диапазону изменения выходных данных обучающей выборки;
    * средней абсолютной ошибкой - скаляр, вычисляется как отношение суммы абсолютных ошибок к размеру выходных данных обучающей выборки;
    * потеря - скаляр, результаты вычисления заданной для сети функции потери.
* обучающей выборкой, которая была использована при обучении;
* временем выполнение - количество миллисекунд, которые заняло выполнение обучения.
## 2 Применённые методы повышения эффективности обучения
Для повышения точности обучения и/или снижения его длительности были применены методы, описанные далее.
### 2.1 Расширение выборки при обучении
Точность воспроизведения функции сетью значительно снижается на границах воспроизведения. Этого можно избежать, искусственно "раздвинув" границы при обучении.
### 2.2 Снижение скорости обучения
При корректировке параметров сети градиент домножается на коэффициент, называемый скоростью обучения. Обычно он лежит в диапазоне (0; 1]. Слишком большое значение скорости не позволит алгоритму обратного распространения ошибки стабилизироваться в глобальном минимуме, а слишком маленькое - увеличит длительность обучения и может привести к застреванию в локальных минимумах. Таким образом, выбор скорости является важным этапом подготовки к обучению. В проекте представлена возможность постепенного снижения скорости обучения от некоторого заданного начального до конечного значение. Снижение скорости выполняется линейно каждую эпоху. Это позволяет в начале обучения не застревать в локальных минимумах, а в конце - стабилизироваться в глобальном минимуме.
### 2.3 Инициализация весов
Веса инициализируются методом Ксавьера. Суть метода заключается в контроле дисперсии нормального распределения при инициализации весов. Обычно веса инициализируются либо с равномерным распределением в некоторых фиксированных границах, либо с нормальным распределением с фиксированными математическим ожиданием и дисперсией. 
При неправильном подборе параметров распределения возникает ситуация, будто бы при прохождении через слои суммарный сигнал домножается на некоторый коэффициент, отличный от единицы. Это может приводить либо к "затуханию" сигналов на последних слоях, либо к их значительному росту в сравнении с исходными данными.
Для предотвращения этого возможно использование нормального закона распределения с нулевым математическим ожиданием и дисперсией, зависящей от конфигурации слоя (его размер и количество входов) следующим образом:
> ``дисперсия`` = 1 / (``количество_входов`` + ``размер_слоя``).

Тогда суммарный сигнал не изменяется при прохождении по слоям сети.
## 3 Дополнительные особенности программного средства
Основа программного средства, связанная непосредственно с обучением сетей, ограничивается классами (и их подклассами):
* models.networks.Network;
* models.layers.Layer;
* models.losses.Loss;
* models.operations.Operation;
* models.optimizers.Optimizer;
* models.trainers.Trainer;
* models.math.Matrix.

Остальная часть проекта призвана упростить получение и обработку результатов обучения.
### 3.1 Сериализация
Для сохранения результатов обучения был реализован механизм сериализации сетей. Настройки сериализации задаются в options.Constants. Сохранение сети происходит в файл. В текущей версии проекта реализовано 2 вида сериализации.
#### 3.1.1 Java сериализация
Java сериализация основана на методах ObjectOutputStream.writeObject и ObjectInputStream.readObject. Для реализации сериализации все составляющие сети были помечены интерфейсом Serializable. Также некоторые атрибуты сети и её компонентов, которые отвечают за хранение промежуточных данных, помечены ключевым словом "transient" для исключения из сериализации - это позволяет значительно снизить объём файла, занимаемый сериализованной сетью. Формат файла - двоичный файл с расширением ".dat".
#### 3.1.2 Yaml-like сериализация
Так как Java-сериализация использует двоичный формат, то сериализованная сеть может быть прочитана исключительно Java-программой с тем же набором классов и не может быть прочитана и/или изменена человеком. Для представления сети в некотором независящем от реализации формате был разработан механизм Yaml-like сериализации. Для исключения зависимостей от внешних библиотек механизм был реализован самостоятельно. В текущей версии механизм имеет ряд ограничений:
* сериализуемый класс должен иметь конструктор без аргументов;
* как сам класс, так и все его поля, не должны иметь внутренних классов.
Основные результаты внедрения данного типа сериализации - предоставление возможности чтения и изменения параметров сети в текстовом формате. Формат файла определён строго - изменения отступов или регистра к невозможности десериализации.

Особенности применения Yaml-like сериализации:
* сериализуемый класс должен быть помечен аннотацией serialization.annotations.YamlSerializable;
* сериализуемые поля класса должны быть помечены аннотацией serialization.annotations.YamlField, которая позволяет задать имя сериализуемого поля, отличная от того, что было определено в классе (по умолчанию они совпадают).

Сериализуемые типы полей:
* int, Integer;
* double, Double;
* boolean, Boolean;
* String;
* перечисления (Enum);
* классы, помеченные аннотацией @YamlSerializable;
* массивы любых размерностей, в основе которых лежат элементы типов, представленных выше;
* коллекции (множества, списки);
* ассоциативные массивы (Map).

##### 3.1.2.1 Примеры сериализации и десериализации
Для (де-)сериализации используются вспомогательные классы (и их потомки): serialization.formatters.Formatter и serialization.wrappers.Wrapper.
Первый задаёт правила вывода (формат отступов, разделителей и т.д.).
Второй - обеспечивает разложение объекта в древоподобный объект, который может быть выведен в нужном формате, при сериализации, а также формирование объекта на основе древоподобного объекта, считанного из Yaml-файла, при десериализации. 
###### 3.1.2.1.1 Объект
Сериализация

    Network network = builder.build();  // см. пример в 2.3.2/2.3.3
    String doubleFormat = "%10.5f";  // формат вывода двоичных чисел
    // форматтер, задающий правила вывода объектов и коллекций
    Formatter formatter = new YamlFormatter(doubleFormat);
    // обёртка над объектом заданного класса
    Wrapper wrapper = WrapperFactory.createWrapper(Network.class, formatter);
    // сериализованная сеть
    String serializedNetwork = wrapper.writeValue(network);
Десериализация

    String serializedNetwork = ...  // чтение файла
    ...  // создание форматтера и враппера так же, как при сериализации
    // десериализованная сеть
    Network network = (Network) wrapper.readValue(serializedNetwork);
    
###### 3.1.2.1.2 Массив объектов
Сериализация

    ExperimentConfiguration[] configs = ...  // получение описаний экспериментов
    String doubleFormat = "%10.5f";  // формат вывода двоичных чисел
    // форматтер, задающий правила вывода объектов и коллекций
    Formatter formatter = new YamlFormatter(doubleFormat);
    // обёртка над объектом заданного класса
    Wrapper wrapper = WrapperFactory.createWrapper(ExperimentConfiguration[].class, formatter);
    // сериализованный массив
    String serializedConfigs = wrapper.writeValue(configs);
Десериализация незначительно осложнена необходимостью глубокого преобразования массива к нужному типу

    String serializedConfigs = ...  // чтение файла
    ...  // создание форматтера и враппера так же, как при сериализации
    // массив в виде объекта
    Object rawConfigs = wrapper.readValue(serializedConfigs);
    // десериализованный массив объектов
    ExperimentConfiguration[] configs = Arrays.stream((Object[]) rawConfigs)
        .map(ExperimentConfiguration.class::cast)
        .toArray(ExperimentConfiguration[]::new);
### 3.2 Автоматизация экспериментов
Для облегчения выполнения серий экспериментов и получения более надёжных результатов были разработаны классы, позволяющие запускать обучение с одинаковыми или разными настройками.
#### 3.2.1 Описание конфигурации запуска
Первой ступенью автоматизации является класс utils.automatization.RunConfiguration. Он представляет собой обёртку над models.trainers.FitParameters и позволяет указать, сколько раз необходимо запустить обучение для данных параметров. Класс содержит поля:
* описание - позволяет задать описание для данной конфигурации;
* количество перезапусков - сколько попыток обучения должно быть выполнено для данных параметров;
* параметры обучения - см. п. 1.4.

Таким образом, класс позволяет несколько раз запускать обучение для одних и тех же настроек, что позволяет получать результаты, менее зависимые от случая (данная зависимость обусловлена случайным характером инициализации параметров сети).
#### 3.2.2 Описание конфигурации эксперимента
Следующей ступенью автоматизации является класс utils.automatization.Experiment. Он представляет собой обёртку над набором конфигураций запуска и позволяет объединять несколько конфигураций в рамках одного эксперимента. Класс содержит поля:
* описание - позволяет задать описание для данного эксперимента;
* массив конфигураций - набор конфигураций, относящихся к данному эксперименту.

Таким образом, класс позволяет запускать несколько конфигураций для изучения влияния каких-либо параметров обучения. Например, в рамках эксперимента "Исследование влияние размера выборки" могут быть объединены конфигурации, отличающиеся исключительно размером выборки.
#### 3.2.3 Предобучение
Обучение обладает определенной непостоянностью ввиду случайности характера инициализации входных параметров сети. Так как результат работы сети зависит от каждого отдельного весового коэффициента, то итоговая точность обучения значительно зависит от начальных значений коэффициентов. Таким образом, возможны ситуации, когда сети с одинаковой топологией, отличающиеся лишь начальными значениями весовых коэффициентов, за одинаковое количество эпох демонстрируют различную точность воспроизведения заданной зависимости.
Для борьбы с таким явлением возможно проведение серии экспериментов. Однако, зачастую некоторые наборы весовых коэффициентов сразу обучаются "эффективнее" (демонстрируют лучшие результаты за меньшее количество эпох) других. Таким образом, возможно сразу отбросить те наборы, которые демонстрируют худшие результаты. Для автоматизации таких экспериментов был введены параметры:
* FitParameters.preTrainRequired - нужно ли выполнять предобучение;
* FitParameters.preTrainCount - количество попыток предобучения;
* FitParameters.preTrainReduceFactor - множитель уменьшения длительности обучения.

Алгоритм предобучения состоит в следующем:
1. Если предобучение не требуется, то обучается единственная сеть в соответствии с полученными параметрами обучения;
2. Иначе создаётся <FitParameters.preTrainCount> экземпляров сетей (с разными весовыми коэффициентами) и столько же копий параметров обучения с уменьшенным в <FitParameters.preTrainReduceFactor> раз количеством эпох;
3. Запускаются заданное количество попыток обучения сетей со сниженным количеством эпох;
4. По завершении обучения выбирается сеть, обеспечившая наилучшие результаты;
5. Запускается обучение для выбранной в предыдущем пункте сети с полным количеством эпох обучения.
#### 3.2.4 Перезапуск конфигурации
Одна конфигурация запуска (характеризуется параметрами обучения) может быть перезапущена несколько раз. В результате перезапусков сохраняется сеть, обеспечившая наилучший результат. Таким образом можно получать наилучшие результаты для заданных настроек обучения и обучающей выборки.
### 3.3 Выбор методики опроса
Во время обучения периодически происходит опрос сети, когда на вход подаются входы из тестовой части обучающей выборки и фиксируется потеря. В контексте решаемой задачи целесообразно выполнять опросы не каждую эпоху, а с некоторыми промежутками. Программное средство предлагает на выбор две методики опроса, представленные элементами перечисления models.trainers.QueriesRangeType:
* LINEAR - опросы происходят через равные промежутки времени;
* NON_LINEAR - опросы происходят через разные промежутки времени (чаще в начале обучения и реже в конце).

За выбор типа отвечает параметр FitParameters.queriesRangeType.
### 3.4 Вынесение общих настроек
Некоторые общие настройки, которые позволяют некоторыми аспектами программы (вывод, сохранение и др.), вынесены в конфигурационный файл "app.properties" и соответствующий ему класс options.AppProperties, а именно:
* признак debug-режима - если true, то вывод формируется более подробный;
* формат вещественных чисел - формат, использующийся при выводе;
* настройки вывода:
    * нужен ли вывод - флаг необходимости вообще всего вывода;
    * параметры для каждого запуска;
    * параметры для лучшего запуска каждой конфигурации;
    * параметры для лучшего запуска конфигурации каждого эксперимента;
    * параметры для лучшего запуска среди всех экспериментов;
> Параметры являются объектами типа models.options.PrintOptions, который позволяет задавать:
> * необходимость вывода - при выводе проверяется как глобальный флаг из models.options.Constants, так и данный флаг;
> * необходимость вывода параметров сети;
> * необходимость вывода результатов обучения сети в виде таблицы;
> * необходимость вывода динамики обучения (зависимость потери от эпохи);
> * выводимая часть таблиц - какую часть таблиц печатать (1.0 - полностью, 0.5 - каждую вторую строчку и т.д.).
>
> Таким образом появляется возможность гибкой настройки объёма выводимой информации.
* настройки сохранения:
    * нужно ли сохранять сети;
    * тип сериализации - объект перечисления models.serialization.SerializationType (JAVA, YAML);
    * папка для сохранения сетей;
    * префикс имён файлов для сохранения сетей;
    * сохранять ли сеть после каждого запуска;
    * сохранять ли сеть после лучшего запуска каждой конфигурации;
    * сохранять ли сеть после лучшего запуска конфигурации каждого эксперимента;
    * сохранять ли сеть после лучшего запуска среди всех экспериментов;
* максимальное количество потоков;
* источник описания экспериментов;
* для Yaml-файла с описанием экспериментов:
    * путь к папке;
    * имя файла.
### 3.5 Профилирование
В программе отслеживается и в формате "ЧАСЫ:МИНУТЫ:СЕКУНДЫ.МИЛИСЕКУНДЫ" выводится время выполнения:
* одной попытки обучения;
* эксперимента;
* всей программы.

### 3.6 Логирование
Вывод программы происходит с помощью фреймворка java.util.logging. В лог выводится запрашиваемая пользователем информация (с уровнем INFO), информация об ошибках (уровень SEVERE), некоторая служебная информация о промежуточных операциях (уровни FINE, FINER, FINEST). 
Настройки логированя хранятся в файле "logging.properties". По умолчанию лог выводится в консоль и в текстовый файл.
Для форматирования логов был разработан класс models.utils.MyLogFormatter. Его отличие от стандартного java.util.logging.SimpleFormatter заключается в следующем:
* изменен формат вывода времени;
* добавлен вывод имени потока, который публикует запись в лог.
### 3.7 Параллелизация
В текущей версии параллельно выполняется обучения в одном эксперименте. 
Эксперимент характеризуется набором конфигураций, каждая из которых может быть перезапущена несколько раз.
При запуске программы подготавливаются и запускаются в отдельных потоках задачи обучения сети. Механизм параллелизации основан на использовании интерфейсов ExecutorService, Callable и Future. После запуска главный поток блокируется и ждёт результатов обучения. Максимальное количество потоков может быть ограничено параметром "thread.pool.size" в конфигурационном файле "app.properties".
## 4 Пути улучшения программного средства
### 4.1 Динамика потерь с предобучением (FIXED)
В текущей версии программного средства при использовании механизма предобучения теряется информация о величине потерь на начальных этапах обучения.
### 4.2 Вынесение настроек в конфигурационные файлы (FIXED)
В текущей версии некоторые настройки задаются в классе models.options.Constants. Из-за этого изменение настроек требует пересборки проекта. Данные настройки необходимо вынести в конфигурационный файл (вероятно, файл будет вычитываться в тот же самый класс).
### 4.3 Вынесение описания экспериментов в текстовый файл (FIXED)
Описание экспериментов задаётся в классе Experiments. Таким образом, при изменении набора экспериментов требуется пересборка проекта. Это описание необходимо вынести в файл (например, в формате YAML).
### 4.4 Изменение отслеживания таймингов (FIXED)
В текущей версии продукта невозможно получение реального времени обработки одного эксперимента, так как его по его подзадачам отслеживается лишь их время выполнения. Необходимо перейти на фиксирование времени начала и времени окончания вместо вычисления этой разницы. В дальнейшем это позволит выбирать для эксперимента минимальное время начало и максимальное время окончания для определения длительности эксперимента.
### 4.5 Введение мутаторов для конфигураций
В рамках эксперимента целесообразно объединять конфигурации, отличающиеся в одном параметре. В описании такого эксперимента дублируется большое количество остальной информации, не относящейся к изменяемому параметру. 
Для снижения дублирования необходимо проработать механизм мутации конфигураций на уровне эксперимента для автоматического формирования конфигураций, аналогичных некоторой базовой конфигурации, отличных в каком-то одном параметре.
Для этого необходимо определить набор изменяемых параметров (например, количество эпох обучения), а также типовые способы их изменения (например, умножение на константу).
Помимо снижения дублирования информации это позволит автоматизировать подбор некоторых гипер-параметров.